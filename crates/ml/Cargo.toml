[package]
name = "parry-ml"
description = "ML-based injection detection (DeBERTa v3)"
version.workspace = true
edition.workspace = true
license.workspace = true
repository.workspace = true
homepage.workspace = true
keywords.workspace = true
categories.workspace = true

[dependencies]
parry-core.workspace = true
eyre.workspace = true
tokenizers.workspace = true
hf-hub.workspace = true
tracing.workspace = true

# ONNX backend (optional)
ort = { workspace = true, optional = true }
ndarray = { workspace = true, optional = true }

# Candle backend (optional)
candle-core = { workspace = true, optional = true }
candle-nn = { workspace = true, optional = true }
candle-transformers = { workspace = true, optional = true }
serde_json.workspace = true

[features]
default = ["candle"]
# ONNX with runtime dylib loading (user provides ORT_DYLIB_PATH)
onnx = ["dep:ort", "dep:ndarray", "ort/load-dynamic"]
# ONNX with auto-download of runtime (self-contained, larger binary)
onnx-fetch = [
  "dep:ort",
  "dep:ndarray",
  "ort/download-binaries",
  "ort/copy-dylibs",
  "ort/tls-native",
]
# ONNX with CoreML acceleration (Apple Silicon)
onnx-coreml = ["onnx-fetch", "ort/coreml"]
# Pure Rust ML backend (no native deps)
candle = ["dep:candle-core", "dep:candle-nn", "dep:candle-transformers"]

[dev-dependencies]
criterion.workspace = true

[package.metadata.docs.rs]
features = ["candle"]

[[bench]]
name = "inference"
harness = false

[lints]
workspace = true
